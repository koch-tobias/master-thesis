@inproceedings{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  month = aug,
  eprint = {1603.02754},
  primaryclass = {cs},
  pages = {785--794},
  doi = {10.1145/2939672.2939785},
  urldate = {2023-10-08},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\q617269\\Zotero\\storage\\5ESI324N\\Chen und Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf;C\:\\Users\\q617269\\Zotero\\storage\\NE76EQLJ\\1603.html}
}
