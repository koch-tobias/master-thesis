@incollection{schapireBoostingApproachMachine2003,
  title = {The {{Boosting Approach}} to {{Machine Learning}}: {{An Overview}}},
  shorttitle = {The {{Boosting Approach}} to {{Machine Learning}}},
  booktitle = {Nonlinear {{Estimation}} and {{Classification}}},
  author = {Schapire, Robert E.},
  editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S. and Denison, David D. and Hansen, Mark H. and Holmes, Christopher C. and Mallick, Bani and Yu, Bin},
  year = {2003},
  volume = {171},
  pages = {149--171},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-21579-2_9},
  urldate = {2023-10-05},
  abstract = {Boosting is a general method for improving the accuracy of any given learning algorithm. Focusing primarily on the AdaBoost algorithm, this chapter overviews some of the recent work on boosting including analyses of AdaBoost's training error and generalization error; boosting's connection to game theory and linear programming; the relationship between boosting and logistic regression; extensions of AdaBoost for multiclass classification problems; methods of incorporating human knowledge into boosting; and experimental and applied work using boosting.},
  isbn = {978-0-387-95471-4 978-0-387-21579-2},
  langid = {english},
  file = {C:\Users\q617269\Zotero\storage\E5RFFADN\Schapire - 2003 - The Boosting Approach to Machine Learning An Over.pdf}
}
