{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "#from copy import deepcopy\n",
    "import os\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_into_df(folder_name: Path) -> list:\n",
    "    '''\n",
    "    This function searches for all .xls files in a given directory, loads each file into a Pandas dataframe and changes the header line\n",
    "    return: List with all created dataframes\n",
    "    '''\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_name):\n",
    "        logger.error(f\"The path {folder_name} does not exist.\")\n",
    "        exit()\n",
    "    else:\n",
    "        logger.info(\"Loading the data...\")\n",
    "\n",
    "        # Create an empty list to store all dataframes\n",
    "        dataframes = []\n",
    "\n",
    "        # Loop through all files in the folder and open them as dataframes\n",
    "        for file in os.listdir(folder_name):\n",
    "            if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "                try:\n",
    "                    # Load the excel into a pandas dataframe, delete the header and declare the second row as new header\n",
    "                    df = pd.read_excel(os.path.join(folder_name, file), header=None, skiprows=1)            \n",
    "                    df.columns = df.iloc[0]\n",
    "                    df = df.iloc[1:]\n",
    "                    \n",
    "                    # Add the created dataframe to the list of dataframes\n",
    "                    dataframes.append(df)\n",
    "                except:\n",
    "                    logger.info(f\"Error reading file {file}. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "    # Check if any dataframes were created\n",
    "    if len(dataframes) == 0:\n",
    "        logger.error(f\"No dataframes were created - please check if the files in folder {folder_name} are correct.\")\n",
    "        exit()\n",
    "    else:\n",
    "        logger.success(f\"{len(dataframes)} dataframe(s) were created.\")\n",
    "\n",
    "        return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(dataframes: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    This function takes a list of data frames as input and checks if the dataframes have the same header. If so, the dataframes will be merged.\n",
    "    return: Merged dataframe\n",
    "    '''\n",
    "    # Set the header information\n",
    "    columns_set = set(dataframes[0].columns)\n",
    "\n",
    "    # Check if all dataframes have the same columns \n",
    "    for df in dataframes:\n",
    "        if set(df.columns) != columns_set:\n",
    "            raise ValueError(\"All dataframes must have the same columns.\")\n",
    "    \n",
    "    # Merge all dataframes into a single dataframe\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    merged_df.to_excel(\"../data/combined_dataset.xlsx\")\n",
    "\n",
    "    logger.success(f\"{len(dataframes)} dataframe(s) are combined to one dataset and stored in a excel file.\")\n",
    "    \n",
    "    return merged_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info_to_excel(df: pd.DataFrame):\n",
    "    '''\n",
    "    This function saves feature informations in an excel file\n",
    "    '''\n",
    "    pd.DataFrame({\"name\": df.columns, \"non-nulls\": len(df)-df.isnull().sum().values, \"nulls\": df.isnull().sum().values, \"type\": df.dtypes.values}).to_excel(\"data_infos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data_folder_dir: Path):\n",
    "\n",
    "    # Load the data into a list of pandas dataframes\n",
    "    dataframes = load_csv_into_df(data_folder_dir)\n",
    "\n",
    "    # Store the ncar abbreviation for file paths\n",
    "    ncar = dataframes[0]['Benennung (dt)'][1][:3]\n",
    "\n",
    "    logger.info(\"Start preprocessing the data...\")\n",
    "  \n",
    "    dataframes_with_labels = []\n",
    "    for i in range(len(dataframes)):\n",
    "        # Keep only the relevant samples with Dok-Format=5P. This samples are on the last level of the car structure\n",
    "        dataframes[i] = dataframes[i][dataframes[i][\"Dok-Format\"]=='5P'].reset_index(drop=True)\n",
    "\n",
    "        # Keep only features which are identified as relevant for the preprocessing, the predictions or for the users' next steps\n",
    "        dataframes[i] = dataframes[i][['Sachnummer','Benennung (dt)', 'X-Min','X-Max','Y-Min','Y-Max','Z-Min','Z-Max', 'Wert','Einheit','Gewichtsart','Kurzname','L-Kz.', 'L/R-Kz.', 'Modul (Nr)', 'ox','oy', 'oz', 'xx','xy','xz', 'yx','yy','yz','zx','zy','zz']]\n",
    "\n",
    "        # Add columns for the label \"Relevant f√ºr Messung\" and \"Allgemeine Bezeichnung\"\n",
    "        data_labeled = dataframes[i]\n",
    "        data_labeled.insert(len(data_labeled.columns), 'Relevant fuer Messung', 'Nein')\n",
    "        data_labeled.insert(len(data_labeled.columns), 'Einheitsname', '')\n",
    "        dataframes_with_labels.append(data_labeled)\n",
    "\n",
    "        # Date\n",
    "        dateTimeObj = datetime.now()\n",
    "        timestamp = dateTimeObj.strftime(\"%d%m%Y_%H%M\")\n",
    "        \n",
    "        # Store preprocessed dataframes\n",
    "        dataframes_with_labels[i].to_excel(f\"../data/preprocessed_data/{ncar}_preprocessed_{timestamp}.xlsx\")\n",
    "\n",
    "    logger.success(f\"The data is succeccfully preprocessed and stored as {ncar}_preprocessed_{timestamp}.xlsx!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the path to the folder containing the data (xls files)\n",
    "    data_folder = Path(\"../data/original_data\")\n",
    "\n",
    "    data_preprocessing(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-26 15:40:57.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_into_df\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mLoading the data...\u001b[0m\n",
      "\u001b[32m2023-04-26 15:40:58.981\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_csv_into_df\u001b[0m:\u001b[36m36\u001b[0m - \u001b[32m\u001b[1m1 dataframe(s) were created.\u001b[0m\n",
      "\u001b[32m2023-04-26 15:40:58.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mdata_preprocessing\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mStart preprocessing the data...\u001b[0m\n",
      "\u001b[32m2023-04-26 15:41:04.831\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mdata_preprocessing\u001b[0m:\u001b[36m32\u001b[0m - \u001b[32m\u001b[1mThe data is succeccfully preprocessed and stored as G65_preprocessed_26042023_1540.xlsx!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMesstool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
